{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide \n",
    "\n",
    "- For data visualization see the file `data_visualization.ipynb`\n",
    "- The preprocessing is done in the file `preprocessing.ipynb`\n",
    "- The benchmark model is in the file `benchmark.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  # for sqrt\n",
    "from statistics import mean\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/course_library/andrea_models.py\n",
    "from andrea_models import AndreaLinearRegression  # In the course library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples  12366 ; Test samples  5300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>station_AD</th>\n",
       "      <th>station_AI</th>\n",
       "      <th>station_AJ</th>\n",
       "      <th>station_AK</th>\n",
       "      <th>station_AM</th>\n",
       "      <th>station_AT</th>\n",
       "      <th>station_AW</th>\n",
       "      <th>station_AX</th>\n",
       "      <th>station_BB</th>\n",
       "      <th>...</th>\n",
       "      <th>p0q3</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week_0.0</th>\n",
       "      <th>day_of_week_1.0</th>\n",
       "      <th>day_of_week_3.0</th>\n",
       "      <th>day_of_week_4.0</th>\n",
       "      <th>day_of_week_2.0</th>\n",
       "      <th>hour_num</th>\n",
       "      <th>p0q0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18052</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23959</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25589</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19182</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19257</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       train  station_AD  station_AI  station_AJ  station_AK  station_AM  \\\n",
       "18052     36           0           0           0           0           0   \n",
       "23959     49           0           0           0           0           0   \n",
       "25589     50           0           0           0           0           0   \n",
       "19182      4           0           0           1           0           0   \n",
       "19257      4           0           0           0           0           1   \n",
       "\n",
       "       station_AT  station_AW  station_AX  station_BB  ...   p0q3  month  day  \\\n",
       "18052           0           0           0           1  ...  0.173      1    9   \n",
       "23959           0           0           0           0  ...  0.056      5   13   \n",
       "25589           0           0           0           0  ...  0.181      1   15   \n",
       "19182           0           0           0           0  ...  0.357      4    3   \n",
       "19257           0           0           0           0  ...  0.171      1   15   \n",
       "\n",
       "       day_of_week_0.0  day_of_week_1.0  day_of_week_3.0  day_of_week_4.0  \\\n",
       "18052                0                0                0                0   \n",
       "23959                1                0                0                0   \n",
       "25589                0                1                0                0   \n",
       "19182                0                0                0                0   \n",
       "19257                0                1                0                0   \n",
       "\n",
       "       day_of_week_2.0  hour_num   p0q0  \n",
       "18052                1       7.0  0.316  \n",
       "23959                0       8.0  0.069  \n",
       "25589                0       9.0  0.214  \n",
       "19182                1       7.0  0.381  \n",
       "19257                0       7.0  0.382  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all lines with missing values\n",
    "processed_training_features = processed_training_features.dropna()\n",
    "\n",
    "df_train, df_test = train_test_split(processed_training_features, test_size=0.3, random_state=25)\n",
    "\n",
    "y_test = df_test['t0s0']\n",
    "\n",
    "print('Training samples ', df_train.shape[0], '; Test samples ', df_test.shape[0])\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols ['train', 'station_AD', 'station_AI', 'station_AJ', 'station_AK', 'station_AM', 'station_AT', 'station_AW', 'station_AX', 'station_BB', 'station_BD', 'station_BE', 'station_AE', 'station_AL', 'station_AO', 'station_AQ', 'station_BC', 'station_AB', 'station_AN', 'station_AS', 'station_BF', 'station_BG', 'station_BH', 'station_AV', 'station_AF', 'station_AP', 'station_AZ', 'station_AA', 'station_AC', 'station_AG', 'station_AH', 'station_AR', 'station_AU', 'station_BA', 'station_BI', 'station_BJ', 'station_AY', 'composition', 'p1q0', 'p2q0', 'p3q0', 'p0q1', 'p0q2', 'p0q3', 'month', 'day', 'day_of_week_0.0', 'day_of_week_1.0', 'day_of_week_3.0', 'day_of_week_4.0', 'day_of_week_2.0', 'hour_num']\n",
      "Number of non-constant features: 40 out of 52\n"
     ]
    }
   ],
   "source": [
    "all_feature_cols = [col for col in df_train.columns if 't0s0' not in col]\n",
    "\n",
    "non_constant_features = feature_engineering.low_var_features(df_train, threshold=0)\n",
    "\n",
    "print(\"Cols\", all_feature_cols)\n",
    "print(\"Number of non-constant features:\", len(non_constant_features), \"out of\", len(all_feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week_0.0</th>\n",
       "      <th>day_of_week_1.0</th>\n",
       "      <th>day_of_week_3.0</th>\n",
       "      <th>day_of_week_4.0</th>\n",
       "      <th>day_of_week_2.0</th>\n",
       "      <th>hour_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.33600</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.315</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.27300</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.264</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.23485</td>\n",
       "      <td>0.259685</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.35900</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.060</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24752</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.40800</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.446</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train  composition   p1q0     p2q0      p3q0   p0q1   p0q2   p0q3  \\\n",
       "3434      14            2  0.452  0.33600  0.353000  0.281  0.371  0.315   \n",
       "7851      21            2  0.327  0.27300  0.388000  0.220  0.312  0.264   \n",
       "5176      18            2  0.181  0.23485  0.259685  0.155  0.104  0.082   \n",
       "15174     31            2  0.295  0.35900  0.368000  0.511  0.423  0.060   \n",
       "24752      5            2  0.394  0.40800  0.457000  0.403  0.464  0.446   \n",
       "\n",
       "       month  day  day_of_week_0.0  day_of_week_1.0  day_of_week_3.0  \\\n",
       "3434       3   20                0                0                0   \n",
       "7851       2   19                0                1                0   \n",
       "5176       5   10                0                0                0   \n",
       "15174      3   28                0                0                1   \n",
       "24752      3   21                0                0                1   \n",
       "\n",
       "       day_of_week_4.0  day_of_week_2.0  hour_num  \n",
       "3434                 0                1       7.0  \n",
       "7851                 0                0       9.0  \n",
       "5176                 1                0       8.0  \n",
       "15174                0                0       7.0  \n",
       "24752                0                0       7.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_station_cols = [col for col in all_feature_cols if 'station' not in col]\n",
    "\n",
    "df_train[non_station_cols].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (12366, 52)\n"
     ]
    }
   ],
   "source": [
    "# Print shape\n",
    "print(\"df_train.shape:\", df_train[all_feature_cols].shape)\n",
    "\n",
    "x_train = df_train[all_feature_cols].values\n",
    "y_train = df_train['t0s0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.935\n",
      "Model:                            OLS   Adj. R-squared:                  0.935\n",
      "Method:                 Least Squares   F-statistic:                     4775.\n",
      "Date:                Wed, 04 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:05:49   Log-Likelihood:                 23486.\n",
      "No. Observations:               12366   AIC:                        -4.690e+04\n",
      "Df Residuals:                   12328   BIC:                        -4.661e+04\n",
      "Df Model:                          37                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "intercept           0.2246      0.023      9.903      0.000       0.180       0.269\n",
      "train               0.0005   3.27e-05     14.201      0.000       0.000       0.001\n",
      "station_AD          0.0291      0.003     11.463      0.000       0.024       0.034\n",
      "station_AI          0.0113      0.002      6.125      0.000       0.008       0.015\n",
      "station_AJ         -0.0056      0.002     -3.706      0.000      -0.009      -0.003\n",
      "station_AK         -0.0242      0.002    -12.697      0.000      -0.028      -0.020\n",
      "station_AM          0.0734      0.002     30.758      0.000       0.069       0.078\n",
      "station_AT          0.0314      0.002     12.971      0.000       0.027       0.036\n",
      "station_AW          0.0149      0.002      6.326      0.000       0.010       0.020\n",
      "station_AX       3.373e-16   3.79e-17      8.911      0.000    2.63e-16    4.12e-16\n",
      "station_BB         -0.0673      0.002    -42.306      0.000      -0.070      -0.064\n",
      "station_BD       9.906e-17   6.07e-18     16.318      0.000    8.72e-17    1.11e-16\n",
      "station_BE      -1.472e-16   1.36e-17    -10.853      0.000   -1.74e-16   -1.21e-16\n",
      "station_AE          0.0311      0.002     13.808      0.000       0.027       0.035\n",
      "station_AL         -0.0094      0.002     -4.127      0.000      -0.014      -0.005\n",
      "station_AO          0.0111      0.002      4.707      0.000       0.006       0.016\n",
      "station_AQ          0.0201      0.002     11.424      0.000       0.017       0.024\n",
      "station_BC          0.0208      0.002      8.528      0.000       0.016       0.026\n",
      "station_AB         -0.0050      0.002     -2.168      0.030      -0.009      -0.000\n",
      "station_AN        3.44e-17   2.68e-18     12.821      0.000    2.91e-17    3.97e-17\n",
      "station_AS      -1.472e-17   1.73e-18     -8.510      0.000   -1.81e-17   -1.13e-17\n",
      "station_BF          0.0098      0.002      4.243      0.000       0.005       0.014\n",
      "station_BG      -1.619e-17   2.67e-18     -6.058      0.000   -2.14e-17    -1.1e-17\n",
      "station_BH          0.0100      0.002      4.234      0.000       0.005       0.015\n",
      "station_AV       1.562e-18   1.35e-18      1.159      0.246   -1.08e-18     4.2e-18\n",
      "station_AF       3.161e-17   1.19e-18     26.547      0.000    2.93e-17    3.39e-17\n",
      "station_AP      -2.309e-17   1.87e-18    -12.326      0.000   -2.68e-17   -1.94e-17\n",
      "station_AZ          0.0546      0.003     19.784      0.000       0.049       0.060\n",
      "station_AA         -0.0127      0.003     -3.641      0.000      -0.019      -0.006\n",
      "station_AC          0.0133      0.002      5.851      0.000       0.009       0.018\n",
      "station_AG          0.0174      0.002      7.365      0.000       0.013       0.022\n",
      "station_AH          0.0239      0.002      9.620      0.000       0.019       0.029\n",
      "station_AR         2.7e-18   2.57e-19     10.487      0.000     2.2e-18     3.2e-18\n",
      "station_AU         -0.0087      0.003     -2.961      0.003      -0.014      -0.003\n",
      "station_BA       1.888e-19   1.91e-19      0.987      0.324   -1.86e-19    5.64e-19\n",
      "station_BI      -6.386e-18    2.5e-19    -25.530      0.000   -6.88e-18    -5.9e-18\n",
      "station_BJ         -0.0147      0.003     -4.300      0.000      -0.021      -0.008\n",
      "station_AY       2.761e-18   2.19e-19     12.582      0.000    2.33e-18    3.19e-18\n",
      "composition        -0.0795      0.014     -5.731      0.000      -0.107      -0.052\n",
      "p1q0                0.0133      0.005      2.651      0.008       0.003       0.023\n",
      "p2q0                0.0615      0.004     13.743      0.000       0.053       0.070\n",
      "p3q0                0.1283      0.004     30.907      0.000       0.120       0.136\n",
      "p0q1                0.3561      0.007     50.819      0.000       0.342       0.370\n",
      "p0q2                0.4020      0.007     53.611      0.000       0.387       0.417\n",
      "p0q3                0.2126      0.005     44.190      0.000       0.203       0.222\n",
      "month              -0.0007      0.000     -2.583      0.010      -0.001      -0.000\n",
      "day              9.334e-05    4.6e-05      2.029      0.042    3.17e-06       0.000\n",
      "day_of_week_0.0     0.0443      0.005      9.671      0.000       0.035       0.053\n",
      "day_of_week_1.0     0.0449      0.005      9.792      0.000       0.036       0.054\n",
      "day_of_week_3.0     0.0470      0.005     10.231      0.000       0.038       0.056\n",
      "day_of_week_4.0     0.0431      0.005      9.378      0.000       0.034       0.052\n",
      "day_of_week_2.0     0.0452      0.005      9.928      0.000       0.036       0.054\n",
      "hour_num           -0.0129      0.001    -25.321      0.000      -0.014      -0.012\n",
      "==============================================================================\n",
      "Omnibus:                     1955.821   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18781.366\n",
      "Skew:                           0.464   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.966   Cond. No.                     1.10e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.25e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "all_features_model = AndreaLinearRegression()\n",
    "all_features_model.fit(x_train, y_train, column_names=all_feature_cols)\n",
    "all_features_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (5300, 52)\n",
      "RMSE now:  0.036931929463619506\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test[all_feature_cols].values\n",
    "\n",
    "print('X_test.shape:', X_test.shape)\n",
    "y_pred = all_features_model.predict(X_test)\n",
    "y_test = df_test['t0s0']\n",
    "\n",
    "\n",
    "RMSE_all_features = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE now: ', RMSE_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17666, 52)\n",
      "(17666,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03649840893705339"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=4, shuffle=True, random_state=5)\n",
    "\n",
    "x = processed_training_features[all_feature_cols].values\n",
    "y = processed_training_features['t0s0'].values\n",
    "\n",
    "# Print shapes\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Cross validation works with score, i.e., the higher the better.\n",
    "# This is why the scoring function is the negative Mean Squared Error.\n",
    "scores = cross_val_score(AndreaLinearRegression(),\n",
    "                         x, y, cv=k_fold,\n",
    "                         scoring='neg_mean_squared_error')\n",
    "math.sqrt(mean(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.773\n",
      "Model:                            OLS   Adj. R-squared:                  0.773\n",
      "Method:                 Least Squares   F-statistic:                 3.003e+04\n",
      "Date:                Wed, 04 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:05:26   Log-Likelihood:                 22577.\n",
      "No. Observations:               17666   AIC:                        -4.515e+04\n",
      "Df Residuals:                   17663   BIC:                        -4.512e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.0746      0.001     57.542      0.000       0.072       0.077\n",
      "p1q0           0.0616      0.004     17.054      0.000       0.055       0.069\n",
      "p0q1           0.9290      0.004    208.333      0.000       0.920       0.938\n",
      "==============================================================================\n",
      "Omnibus:                     1927.754   Durbin-Watson:                   0.331\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3926.288\n",
      "Skew:                           0.699   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.838   Cond. No.                         10.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Creating benchmark model with two features\n",
    "x_cols = ['t1s0', 't0s1']\n",
    "\n",
    "bench_mark_model = AndreaLinearRegression()\n",
    "bench_mark_model.fit(processed_training_features[x_cols], processed_training_features['t0s0'], column_names=x_cols)\n",
    "bench_mark_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE benchmark: 0.3637260929368378\n"
     ]
    }
   ],
   "source": [
    "# Test the benchmark model\n",
    "df_test_preprocessed = preprocess_data(x_test, y_sample)\n",
    "df_test_preprocessed = df_test_preprocessed.dropna()\n",
    "\n",
    "X_test = df_test_preprocessed[x_cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "y_pred = bench_mark_model.predict(X_test)\n",
    "\n",
    "RMSE_2_features = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE benchmark:', RMSE_2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (12366, 52)\n",
      "df_test.shape: (5300, 52)\n",
      "(7873, 52)\n",
      "RMSE benchmark: 0.37089927796869887\n"
     ]
    }
   ],
   "source": [
    "# Ensure df_test_preprocessed has the same columns as df_train\n",
    "X_test = df_test_preprocessed[all_feature_cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "print(\"df_train.shape:\", df_train[all_feature_cols].shape)\n",
    "\n",
    "\n",
    "# Print shape\n",
    "print(\"df_test.shape:\", df_test[all_feature_cols].shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "y_pred = all_features_model.predict(X_test)\n",
    "\n",
    "RMSE_all_features = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE benchmark:', RMSE_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK with all features we do not beat the benchmark. Let's try to remove some features and see if we can improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.889\n",
      "Model:                            OLS   Adj. R-squared:                  0.889\n",
      "Method:                 Least Squares   F-statistic:                 2.015e+04\n",
      "Date:                Mon, 25 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:06:27   Log-Likelihood:                 28886.\n",
      "No. Observations:               17666   AIC:                        -5.776e+04\n",
      "Df Residuals:                   17658   BIC:                        -5.769e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.1190      0.004     30.902      0.000       0.111       0.127\n",
      "p0q1           0.3922      0.006     65.686      0.000       0.380       0.404\n",
      "p0q2           0.2975      0.006     46.577      0.000       0.285       0.310\n",
      "p0q3           0.2303      0.004     57.383      0.000       0.222       0.238\n",
      "p1q0          -0.0628      0.003    -19.015      0.000      -0.069      -0.056\n",
      "p3q0           0.1623      0.004     44.925      0.000       0.155       0.169\n",
      "p2q0           0.0978      0.004     26.340      0.000       0.091       0.105\n",
      "hour_num      -0.0106      0.001    -20.474      0.000      -0.012      -0.010\n",
      "==============================================================================\n",
      "Omnibus:                     1444.350   Durbin-Watson:                   0.607\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8576.014\n",
      "Skew:                           0.115   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.406   Cond. No.                         182.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "RMSE 6 features: 0.3680455642563421\n"
     ]
    }
   ],
   "source": [
    "# Most correlated features with t0s0\n",
    "# t0s1               0.88\n",
    "# t0s2               0.88\n",
    "# t0s3               0.78\n",
    "# t1s0               0.67\n",
    "# t3s0               0.59\n",
    "# t2s0               0.53\n",
    "# hour_num           0.29\n",
    "\n",
    "cols = ['t0s1', 't0s2', 't0s3', 't1s0', 't3s0', 't2s0', 'hour_num']\n",
    "\n",
    "model_6_features = AndreaLinearRegression()\n",
    "model_6_features.fit(processed_training_features[cols], processed_training_features['t0s0'], column_names=cols)\n",
    "model_6_features.summary()\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "y_pred = model_6_features.predict(X_test)\n",
    "\n",
    "RMSE_6_features = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE 6 features:', RMSE_6_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.862\n",
      "Model:                            OLS   Adj. R-squared:                  0.862\n",
      "Method:                 Least Squares   F-statistic:                 3.689e+04\n",
      "Date:                Mon, 25 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:08:01   Log-Likelihood:                 27007.\n",
      "No. Observations:               17666   AIC:                        -5.401e+04\n",
      "Df Residuals:                   17662   BIC:                        -5.397e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.0773      0.001     85.652      0.000       0.076       0.079\n",
      "p0q1           0.4400      0.007     67.336      0.000       0.427       0.453\n",
      "p0q2           0.3264      0.007     47.769      0.000       0.313       0.340\n",
      "p0q3           0.2533      0.004     58.103      0.000       0.245       0.262\n",
      "==============================================================================\n",
      "Omnibus:                      917.890   Durbin-Watson:                   0.443\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2439.763\n",
      "Skew:                           0.280   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.732   Cond. No.                         25.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "RMSE 3 features: 0.3652511659648454\n"
     ]
    }
   ],
   "source": [
    "cols = ['t0s1', 't0s2', 't0s3']\n",
    "\n",
    "model_3_features = AndreaLinearRegression()\n",
    "model_3_features.fit(processed_training_features[cols], processed_training_features['t0s0'], column_names=cols)\n",
    "model_3_features.summary()\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "y_pred = model_3_features.predict(X_test)\n",
    "\n",
    "RMSE_6_features = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE 3 features:', RMSE_6_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.836\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                 3.004e+04\n",
      "Date:                Mon, 25 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:08:14   Log-Likelihood:                 25465.\n",
      "No. Observations:               17666   AIC:                        -5.092e+04\n",
      "Df Residuals:                   17662   BIC:                        -5.089e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.0812      0.001     73.623      0.000       0.079       0.083\n",
      "p0q1           0.4284      0.007     59.983      0.000       0.414       0.442\n",
      "p0q2           0.5339      0.006     82.653      0.000       0.521       0.547\n",
      "p1q0           0.0077      0.003      2.465      0.014       0.002       0.014\n",
      "==============================================================================\n",
      "Omnibus:                      674.296   Durbin-Watson:                   0.373\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1853.769\n",
      "Skew:                           0.145   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.560   Cond. No.                         24.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "RMSE 3 features: 0.3646416711941558\n"
     ]
    }
   ],
   "source": [
    "cols = ['t0s1', 't0s2', 't1s0']\n",
    "\n",
    "model_3_features = AndreaLinearRegression()\n",
    "model_3_features.fit(processed_training_features[cols], processed_training_features['t0s0'], column_names=cols)\n",
    "model_3_features.summary()\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "y_pred = model_3_features.predict(X_test)\n",
    "\n",
    "RMSE_6_features = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE 3 features:', RMSE_6_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polinomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': KFold(n_splits=5, random_state=6, shuffle=True),\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('polynomialfeatures',\n",
       "   PolynomialFeatures(include_bias=False)),\n",
       "  ('andrealinearregression', AndreaLinearRegression())],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__polynomialfeatures': PolynomialFeatures(include_bias=False),\n",
       " 'estimator__andrealinearregression': AndreaLinearRegression(),\n",
       " 'estimator__polynomialfeatures__degree': 2,\n",
       " 'estimator__polynomialfeatures__include_bias': False,\n",
       " 'estimator__polynomialfeatures__interaction_only': False,\n",
       " 'estimator__polynomialfeatures__order': 'C',\n",
       " 'estimator__andrealinearregression__fit_intercept': True,\n",
       " 'estimator': Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(include_bias=False)),\n",
       "                 ('andrealinearregression', AndreaLinearRegression())]),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'polynomialfeatures__degree': array([1, 2, 3, 4])},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': 'neg_mean_squared_error',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_test = {'polynomialfeatures__degree': np.arange(1, 5)}\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=6)\n",
    "\n",
    "grid = GridSearchCV(MyPolynomialRegression(), parameters_to_test,\n",
    "                   cv = k_fold, scoring='neg_mean_squared_error')\n",
    "grid.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=6, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;polynomialfeatures&#x27;,\n",
       "                                        PolynomialFeatures(include_bias=False)),\n",
       "                                       (&#x27;andrealinearregression&#x27;,\n",
       "                                        AndreaLinearRegression())]),\n",
       "             param_grid={&#x27;polynomialfeatures__degree&#x27;: array([1, 2, 3, 4])},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=6, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;polynomialfeatures&#x27;,\n",
       "                                        PolynomialFeatures(include_bias=False)),\n",
       "                                       (&#x27;andrealinearregression&#x27;,\n",
       "                                        AndreaLinearRegression())]),\n",
       "             param_grid={&#x27;polynomialfeatures__degree&#x27;: array([1, 2, 3, 4])},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;polynomialfeatures&#x27;,\n",
       "                 PolynomialFeatures(degree=3, include_bias=False)),\n",
       "                (&#x27;andrealinearregression&#x27;, AndreaLinearRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PolynomialFeatures<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">?<span>Documentation for PolynomialFeatures</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PolynomialFeatures(degree=3, include_bias=False)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">AndreaLinearRegression</label><div class=\"sk-toggleable__content fitted\"><pre>AndreaLinearRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=6, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures(include_bias=False)),\n",
       "                                       ('andrealinearregression',\n",
       "                                        AndreaLinearRegression())]),\n",
       "             param_grid={'polynomialfeatures__degree': array([1, 2, 3, 4])},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['t0s1', 't0s2', 't0s3', 't1s0', 't3s0', 't2s0', 'hour_num']\n",
    "\n",
    "grid.fit(processed_training_features[cols],\n",
    "         processed_training_features['t0s0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'polynomialfeatures__degree': 3}\n",
      "Best score: 0.039506539091853095\n",
      "RMSE:  0.3708946675458219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', math.sqrt(mean(-grid.cv_results_['mean_test_score'])))\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "model.fit(processed_training_features[cols],\n",
    "          processed_training_features['t0s0'])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE benchmark: 0.37089927796869887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'polynomialfeatures__degree': 3}\n",
      "Best score: 0.04422282003750794\n",
      "RMSE:  0.37003641739233045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cols = ['t0s1', 't0s2', 't0s3', 't1s0']\n",
    "\n",
    "grid.fit(processed_training_features[cols],\n",
    "         processed_training_features['t0s0'])\n",
    "\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', math.sqrt(mean(-grid.cv_results_['mean_test_score'])))\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "model.fit(processed_training_features[cols],\n",
    "          processed_training_features['t0s0'])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'polynomialfeatures__degree': 4}\n",
      "Best score: 0.06427606277353014\n",
      "RMSE:  0.3659845303148313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cols = ['t0s1', 't1s0', 'hour_num']\n",
    "\n",
    "grid.fit(processed_training_features[cols],\n",
    "         processed_training_features['t0s0'])\n",
    "\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', math.sqrt(mean(-grid.cv_results_['mean_test_score'])))\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "model.fit(processed_training_features[cols],\n",
    "          processed_training_features['t0s0'])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'polynomialfeatures__degree': 4}\n",
      "Best score: 0.06512877916708086\n",
      "RMSE:  0.36582191191669594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cols = ['t0s1', 't1s0']\n",
    "\n",
    "grid.fit(processed_training_features[cols],\n",
    "         processed_training_features['t0s0'])\n",
    "\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', math.sqrt(mean(-grid.cv_results_['mean_test_score'])))\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "\n",
    "model.fit(processed_training_features[cols],\n",
    "          processed_training_features['t0s0'])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Random Forest: 0.36820457908697823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the columns to use\n",
    "cols = ['t0s1', 't1s0', 'hour_num']\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200, random_state=42, criterion='squared_error')\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(processed_training_features[cols],\n",
    "             processed_training_features['t0s0'])\n",
    "\n",
    "# Predict on the test set\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE_rf = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE Random Forest:', RMSE_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Random Forest: 0.3681583704706255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the columns to use\n",
    "cols = ['t0s1', 't1s0']\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200, random_state=42, criterion='squared_error')\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(processed_training_features[cols],\n",
    "             processed_training_features['t0s0'])\n",
    "\n",
    "# Predict on the test set\n",
    "X_test = df_test_preprocessed[cols].values\n",
    "y_test = df_test_preprocessed['t0s0']\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE_rf = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE Random Forest:', RMSE_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Random Forest with all features: 0.37141070591504144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to use (all features)\n",
    "all_features = all_feature_cols.copy()\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model_all_features = RandomForestRegressor(\n",
    "    n_estimators=100, random_state=42, criterion='squared_error')\n",
    "\n",
    "# Fit the model\n",
    "rf_model_all_features.fit(processed_training_features[all_features],\n",
    "                          processed_training_features['t0s0'])\n",
    "\n",
    "# Predict on the test set\n",
    "X_test_all_features = df_test_preprocessed[all_features].values\n",
    "y_test_all_features = df_test_preprocessed['t0s0']\n",
    "y_pred_all_features = rf_model_all_features.predict(X_test_all_features)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE_rf_all_features = np.sqrt(mean_squared_error(y_test_all_features, y_pred_all_features))\n",
    "print('RMSE Random Forest with all features:', RMSE_rf_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2.2885 - mse: 2.2885 - val_loss: 0.1531 - val_mse: 0.1531\n",
      "Epoch 2/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 3/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.1364 - val_mse: 0.1364\n",
      "Epoch 4/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.1429 - val_mse: 0.1429\n",
      "Epoch 5/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.1363 - val_mse: 0.1363\n",
      "Epoch 6/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.1463 - val_mse: 0.1463\n",
      "Epoch 7/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.1459 - val_mse: 0.1459\n",
      "Epoch 8/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.1525 - val_mse: 0.1525\n",
      "Epoch 9/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.1400 - val_mse: 0.1400\n",
      "Epoch 10/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.1472 - val_mse: 0.1472\n",
      "Epoch 11/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.1383 - val_mse: 0.1383\n",
      "Epoch 12/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.1493 - val_mse: 0.1493\n",
      "Epoch 13/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.1406 - val_mse: 0.1406\n",
      "Epoch 14/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.1259 - val_mse: 0.1259\n",
      "Epoch 15/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 16/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 17/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 18/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.1505 - val_mse: 0.1505\n",
      "Epoch 19/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.1467 - val_mse: 0.1467\n",
      "Epoch 20/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.1528 - val_mse: 0.1528\n",
      "Epoch 21/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.1373 - val_mse: 0.1373\n",
      "Epoch 22/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 23/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.1336 - val_mse: 0.1336\n",
      "Epoch 24/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.1290 - val_mse: 0.1290\n",
      "Epoch 25/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.1328 - val_mse: 0.1328\n",
      "Epoch 26/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.1317 - val_mse: 0.1317\n",
      "Epoch 27/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.1307 - val_mse: 0.1307\n",
      "Epoch 28/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 29/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.1325 - val_mse: 0.1325\n",
      "Epoch 30/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.1471 - val_mse: 0.1471\n",
      "Epoch 31/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.1324 - val_mse: 0.1324\n",
      "Epoch 32/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 33/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.8849e-04 - mse: 9.8849e-04 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 34/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.1475 - val_mse: 0.1475\n",
      "Epoch 35/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.1428 - val_mse: 0.1428\n",
      "Epoch 36/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.1435 - val_mse: 0.1435\n",
      "Epoch 37/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.1418 - val_mse: 0.1418\n",
      "Epoch 38/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.1415 - val_mse: 0.1415\n",
      "Epoch 39/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.8972e-04 - mse: 8.8972e-04 - val_loss: 0.1342 - val_mse: 0.1342\n",
      "Epoch 40/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.2470e-04 - mse: 9.2470e-04 - val_loss: 0.1430 - val_mse: 0.1430\n",
      "Epoch 41/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.5110e-04 - mse: 9.5110e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 42/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.3441e-04 - mse: 8.3441e-04 - val_loss: 0.1319 - val_mse: 0.1319\n",
      "Epoch 43/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.0229e-04 - mse: 9.0229e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 44/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.8834e-04 - mse: 8.8834e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 45/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.6532e-04 - mse: 8.6532e-04 - val_loss: 0.1341 - val_mse: 0.1341\n",
      "Epoch 46/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.1872e-04 - mse: 9.1872e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 47/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.6848e-04 - mse: 7.6848e-04 - val_loss: 0.1351 - val_mse: 0.1351\n",
      "Epoch 48/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.7045e-04 - mse: 8.7045e-04 - val_loss: 0.1433 - val_mse: 0.1433\n",
      "Epoch 49/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.2040e-04 - mse: 8.2040e-04 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 50/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.7498e-04 - mse: 7.7498e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 51/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.8360e-04 - mse: 7.8360e-04 - val_loss: 0.1317 - val_mse: 0.1317\n",
      "Epoch 52/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.1452e-04 - mse: 9.1452e-04 - val_loss: 0.1430 - val_mse: 0.1430\n",
      "Epoch 53/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.8781e-04 - mse: 7.8781e-04 - val_loss: 0.1354 - val_mse: 0.1354\n",
      "Epoch 54/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.2787e-04 - mse: 7.2787e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 55/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.9882e-04 - mse: 7.9882e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 56/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.0617e-04 - mse: 8.0617e-04 - val_loss: 0.1365 - val_mse: 0.1365\n",
      "Epoch 57/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.6467e-04 - mse: 7.6467e-04 - val_loss: 0.1337 - val_mse: 0.1337\n",
      "Epoch 58/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.2713e-04 - mse: 7.2713e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 59/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3644e-04 - mse: 7.3644e-04 - val_loss: 0.1382 - val_mse: 0.1382\n",
      "Epoch 60/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.0344e-04 - mse: 7.0344e-04 - val_loss: 0.1386 - val_mse: 0.1386\n",
      "Epoch 61/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.0411e-04 - mse: 7.0411e-04 - val_loss: 0.1441 - val_mse: 0.1441\n",
      "Epoch 62/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.9782e-04 - mse: 7.9782e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 63/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3868e-04 - mse: 7.3868e-04 - val_loss: 0.1340 - val_mse: 0.1340\n",
      "Epoch 64/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.3890e-04 - mse: 7.3890e-04 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 65/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.7636e-04 - mse: 7.7636e-04 - val_loss: 0.1417 - val_mse: 0.1417\n",
      "Epoch 66/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.9994e-04 - mse: 6.9994e-04 - val_loss: 0.1435 - val_mse: 0.1435\n",
      "Epoch 67/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.8295e-04 - mse: 6.8295e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 68/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.1236e-04 - mse: 7.1236e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 69/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.1803e-04 - mse: 7.1803e-04 - val_loss: 0.1366 - val_mse: 0.1366\n",
      "Epoch 70/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.8252e-04 - mse: 6.8252e-04 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 71/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3748e-04 - mse: 7.3748e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 72/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.3081e-04 - mse: 6.3081e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 73/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.4935e-04 - mse: 6.4935e-04 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 74/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.3235e-04 - mse: 6.3235e-04 - val_loss: 0.1431 - val_mse: 0.1431\n",
      "Epoch 75/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6532e-04 - mse: 6.6532e-04 - val_loss: 0.1354 - val_mse: 0.1354\n",
      "Epoch 76/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6579e-04 - mse: 6.6579e-04 - val_loss: 0.1292 - val_mse: 0.1292\n",
      "Epoch 77/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.9706e-04 - mse: 6.9706e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 78/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.5819e-04 - mse: 6.5819e-04 - val_loss: 0.1360 - val_mse: 0.1360\n",
      "Epoch 79/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6234e-04 - mse: 6.6234e-04 - val_loss: 0.1327 - val_mse: 0.1327\n",
      "Epoch 80/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.4976e-04 - mse: 6.4976e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 81/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.0889e-04 - mse: 6.0889e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 82/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.5769e-04 - mse: 6.5769e-04 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 83/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.9465e-04 - mse: 5.9465e-04 - val_loss: 0.1329 - val_mse: 0.1329\n",
      "Epoch 84/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.4607e-04 - mse: 6.4607e-04 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 85/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.2963e-04 - mse: 6.2963e-04 - val_loss: 0.1351 - val_mse: 0.1351\n",
      "Epoch 86/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7086e-04 - mse: 5.7086e-04 - val_loss: 0.1427 - val_mse: 0.1427\n",
      "Epoch 87/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7817e-04 - mse: 5.7817e-04 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 88/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.9829e-04 - mse: 5.9829e-04 - val_loss: 0.1424 - val_mse: 0.1424\n",
      "Epoch 89/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.2097e-04 - mse: 6.2097e-04 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 90/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.7443e-04 - mse: 5.7443e-04 - val_loss: 0.1341 - val_mse: 0.1341\n",
      "Epoch 91/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.0600e-04 - mse: 6.0600e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 92/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8208e-04 - mse: 5.8208e-04 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 93/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.2897e-04 - mse: 6.2897e-04 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 94/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.9222e-04 - mse: 5.9222e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 95/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4396e-04 - mse: 5.4396e-04 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 96/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8985e-04 - mse: 5.8985e-04 - val_loss: 0.1341 - val_mse: 0.1341\n",
      "Epoch 97/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7000e-04 - mse: 5.7000e-04 - val_loss: 0.1436 - val_mse: 0.1436\n",
      "Epoch 98/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.6064e-04 - mse: 6.6064e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 99/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.5670e-04 - mse: 5.5670e-04 - val_loss: 0.1406 - val_mse: 0.1406\n",
      "Epoch 100/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.4017e-04 - mse: 6.4017e-04 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 101/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.0260e-04 - mse: 6.0260e-04 - val_loss: 0.1411 - val_mse: 0.1411\n",
      "Epoch 102/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8475e-04 - mse: 5.8475e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 103/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6303e-04 - mse: 5.6303e-04 - val_loss: 0.1426 - val_mse: 0.1426\n",
      "Epoch 104/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6390e-04 - mse: 5.6390e-04 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 105/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4837e-04 - mse: 5.4837e-04 - val_loss: 0.1339 - val_mse: 0.1339\n",
      "Epoch 106/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.8825e-04 - mse: 5.8825e-04 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 107/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.0645e-04 - mse: 6.0645e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 108/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6222e-04 - mse: 5.6222e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 109/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6841e-04 - mse: 5.6841e-04 - val_loss: 0.1436 - val_mse: 0.1436\n",
      "Epoch 110/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7176e-04 - mse: 5.7176e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 111/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3509e-04 - mse: 5.3509e-04 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 112/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4703e-04 - mse: 5.4703e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 113/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6466e-04 - mse: 5.6466e-04 - val_loss: 0.1354 - val_mse: 0.1354\n",
      "Epoch 114/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3381e-04 - mse: 5.3381e-04 - val_loss: 0.1400 - val_mse: 0.1400\n",
      "Epoch 115/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3604e-04 - mse: 5.3604e-04 - val_loss: 0.1359 - val_mse: 0.1359\n",
      "Epoch 116/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3328e-04 - mse: 5.3328e-04 - val_loss: 0.1388 - val_mse: 0.1388\n",
      "Epoch 117/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3882e-04 - mse: 5.3882e-04 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 118/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.5316e-04 - mse: 5.5316e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 119/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.2989e-04 - mse: 5.2989e-04 - val_loss: 0.1399 - val_mse: 0.1399\n",
      "Epoch 120/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.5192e-04 - mse: 5.5192e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 121/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1719e-04 - mse: 5.1719e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 122/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.1016e-04 - mse: 5.1016e-04 - val_loss: 0.1334 - val_mse: 0.1334\n",
      "Epoch 123/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.9093e-04 - mse: 4.9093e-04 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 124/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8523e-04 - mse: 4.8523e-04 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 125/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3002e-04 - mse: 5.3002e-04 - val_loss: 0.1365 - val_mse: 0.1365\n",
      "Epoch 126/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.1766e-04 - mse: 5.1766e-04 - val_loss: 0.1388 - val_mse: 0.1388\n",
      "Epoch 127/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.0333e-04 - mse: 5.0333e-04 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 128/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4217e-04 - mse: 5.4217e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 129/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1945e-04 - mse: 5.1945e-04 - val_loss: 0.1422 - val_mse: 0.1422\n",
      "Epoch 130/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7998e-04 - mse: 5.7998e-04 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 131/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3999e-04 - mse: 5.3999e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 132/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.0506e-04 - mse: 5.0506e-04 - val_loss: 0.1365 - val_mse: 0.1365\n",
      "Epoch 133/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.9428e-04 - mse: 4.9428e-04 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 134/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.1659e-04 - mse: 5.1659e-04 - val_loss: 0.1400 - val_mse: 0.1400\n",
      "Epoch 135/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0677e-04 - mse: 5.0677e-04 - val_loss: 0.1383 - val_mse: 0.1383\n",
      "Epoch 136/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4479e-04 - mse: 5.4479e-04 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 137/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3507e-04 - mse: 5.3507e-04 - val_loss: 0.1427 - val_mse: 0.1427\n",
      "Epoch 138/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.0866e-04 - mse: 5.0866e-04 - val_loss: 0.1392 - val_mse: 0.1392\n",
      "Epoch 139/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.2320e-04 - mse: 5.2320e-04 - val_loss: 0.1405 - val_mse: 0.1405\n",
      "Epoch 140/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8799e-04 - mse: 4.8799e-04 - val_loss: 0.1399 - val_mse: 0.1399\n",
      "Epoch 141/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1932e-04 - mse: 5.1932e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 142/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5873e-04 - mse: 4.5873e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 143/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4693e-04 - mse: 5.4693e-04 - val_loss: 0.1406 - val_mse: 0.1406\n",
      "Epoch 144/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.9295e-04 - mse: 4.9295e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 145/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4930e-04 - mse: 5.4930e-04 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 146/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.7497e-04 - mse: 4.7497e-04 - val_loss: 0.1408 - val_mse: 0.1408\n",
      "Epoch 147/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6531e-04 - mse: 5.6531e-04 - val_loss: 0.1407 - val_mse: 0.1407\n",
      "Epoch 148/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0324e-04 - mse: 5.0324e-04 - val_loss: 0.1356 - val_mse: 0.1356\n",
      "Epoch 149/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0510e-04 - mse: 5.0510e-04 - val_loss: 0.1456 - val_mse: 0.1456\n",
      "Epoch 150/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.2146e-04 - mse: 5.2146e-04 - val_loss: 0.1343 - val_mse: 0.1343\n",
      "Epoch 151/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6868e-04 - mse: 4.6868e-04 - val_loss: 0.1383 - val_mse: 0.1383\n",
      "Epoch 152/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9940e-04 - mse: 4.9940e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 153/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9789e-04 - mse: 4.9789e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 154/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7703e-04 - mse: 4.7703e-04 - val_loss: 0.1439 - val_mse: 0.1439\n",
      "Epoch 155/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7281e-04 - mse: 4.7281e-04 - val_loss: 0.1342 - val_mse: 0.1342\n",
      "Epoch 156/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6008e-04 - mse: 5.6008e-04 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 157/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6848e-04 - mse: 4.6848e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 158/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8077e-04 - mse: 4.8077e-04 - val_loss: 0.1340 - val_mse: 0.1340\n",
      "Epoch 159/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.9595e-04 - mse: 4.9595e-04 - val_loss: 0.1359 - val_mse: 0.1359\n",
      "Epoch 160/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.7735e-04 - mse: 4.7735e-04 - val_loss: 0.1344 - val_mse: 0.1344\n",
      "Epoch 161/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0615e-04 - mse: 5.0615e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 162/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7370e-04 - mse: 4.7370e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 163/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0107e-04 - mse: 5.0107e-04 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 164/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6987e-04 - mse: 4.6987e-04 - val_loss: 0.1398 - val_mse: 0.1398\n",
      "Epoch 165/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7366e-04 - mse: 4.7366e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 166/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8829e-04 - mse: 4.8829e-04 - val_loss: 0.1358 - val_mse: 0.1358\n",
      "Epoch 167/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.1374e-04 - mse: 4.1374e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 168/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9708e-04 - mse: 4.9708e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 169/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.4499e-04 - mse: 4.4499e-04 - val_loss: 0.1356 - val_mse: 0.1356\n",
      "Epoch 170/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9858e-04 - mse: 4.9858e-04 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 171/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8385e-04 - mse: 4.8385e-04 - val_loss: 0.1357 - val_mse: 0.1357\n",
      "Epoch 172/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8990e-04 - mse: 4.8990e-04 - val_loss: 0.1394 - val_mse: 0.1394\n",
      "Epoch 173/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.6587e-04 - mse: 4.6587e-04 - val_loss: 0.1421 - val_mse: 0.1421\n",
      "Epoch 174/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9637e-04 - mse: 4.9637e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 175/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.1529e-04 - mse: 4.1529e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 176/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8941e-04 - mse: 5.8941e-04 - val_loss: 0.1367 - val_mse: 0.1367\n",
      "Epoch 177/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.3976e-04 - mse: 4.3976e-04 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 178/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7562e-04 - mse: 4.7562e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 179/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5916e-04 - mse: 4.5916e-04 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 180/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.7381e-04 - mse: 4.7381e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 181/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.6712e-04 - mse: 4.6712e-04 - val_loss: 0.1425 - val_mse: 0.1425\n",
      "Epoch 182/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.3963e-04 - mse: 4.3963e-04 - val_loss: 0.1411 - val_mse: 0.1411\n",
      "Epoch 183/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1348e-04 - mse: 5.1348e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 184/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5654e-04 - mse: 4.5654e-04 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 185/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7353e-04 - mse: 4.7353e-04 - val_loss: 0.1408 - val_mse: 0.1408\n",
      "Epoch 186/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.3946e-04 - mse: 4.3946e-04 - val_loss: 0.1344 - val_mse: 0.1344\n",
      "Epoch 187/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8654e-04 - mse: 4.8654e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 188/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.2331e-04 - mse: 5.2331e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 189/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2035e-04 - mse: 4.2035e-04 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 190/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7516e-04 - mse: 4.7516e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 191/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4088e-04 - mse: 4.4088e-04 - val_loss: 0.1330 - val_mse: 0.1330\n",
      "Epoch 192/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.2800e-04 - mse: 5.2800e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 193/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3284e-04 - mse: 4.3284e-04 - val_loss: 0.1393 - val_mse: 0.1393\n",
      "Epoch 194/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5190e-04 - mse: 4.5190e-04 - val_loss: 0.1350 - val_mse: 0.1350\n",
      "Epoch 195/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3982e-04 - mse: 4.3982e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 196/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2701e-04 - mse: 4.2701e-04 - val_loss: 0.1347 - val_mse: 0.1347\n",
      "Epoch 197/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.2714e-04 - mse: 4.2714e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 198/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7484e-04 - mse: 4.7484e-04 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 199/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.2858e-04 - mse: 4.2858e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 200/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2148e-04 - mse: 4.2148e-04 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 201/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5208e-04 - mse: 4.5208e-04 - val_loss: 0.1345 - val_mse: 0.1345\n",
      "Epoch 202/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8244e-04 - mse: 4.8244e-04 - val_loss: 0.1426 - val_mse: 0.1426\n",
      "Epoch 203/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4431e-04 - mse: 4.4431e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 204/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1497e-04 - mse: 4.1497e-04 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 205/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4322e-04 - mse: 4.4322e-04 - val_loss: 0.1336 - val_mse: 0.1336\n",
      "Epoch 206/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4021e-04 - mse: 4.4021e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 207/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9390e-04 - mse: 4.9390e-04 - val_loss: 0.1430 - val_mse: 0.1430\n",
      "Epoch 208/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2445e-04 - mse: 4.2445e-04 - val_loss: 0.1332 - val_mse: 0.1332\n",
      "Epoch 209/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5373e-04 - mse: 4.5373e-04 - val_loss: 0.1414 - val_mse: 0.1414\n",
      "Epoch 210/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6492e-04 - mse: 4.6492e-04 - val_loss: 0.1386 - val_mse: 0.1386\n",
      "Epoch 211/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4844e-04 - mse: 4.4844e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 212/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6139e-04 - mse: 4.6139e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 213/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3858e-04 - mse: 4.3858e-04 - val_loss: 0.1367 - val_mse: 0.1367\n",
      "Epoch 214/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1484e-04 - mse: 4.1484e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 215/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3177e-04 - mse: 4.3177e-04 - val_loss: 0.1449 - val_mse: 0.1449\n",
      "Epoch 216/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4659e-04 - mse: 4.4659e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 217/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4160e-04 - mse: 4.4160e-04 - val_loss: 0.1425 - val_mse: 0.1425\n",
      "Epoch 218/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.2599e-04 - mse: 4.2599e-04 - val_loss: 0.1350 - val_mse: 0.1350\n",
      "Epoch 219/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3355e-04 - mse: 4.3355e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 220/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5546e-04 - mse: 4.5546e-04 - val_loss: 0.1366 - val_mse: 0.1366\n",
      "Epoch 221/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.1606e-04 - mse: 4.1606e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 222/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0832e-04 - mse: 4.0832e-04 - val_loss: 0.1406 - val_mse: 0.1406\n",
      "Epoch 223/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2412e-04 - mse: 4.2412e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 224/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2723e-04 - mse: 4.2723e-04 - val_loss: 0.1388 - val_mse: 0.1388\n",
      "Epoch 225/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3367e-04 - mse: 4.3367e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 226/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5663e-04 - mse: 4.5663e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 227/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9145e-04 - mse: 3.9145e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 228/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1686e-04 - mse: 4.1686e-04 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 229/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0270e-04 - mse: 4.0270e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 230/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9767e-04 - mse: 3.9767e-04 - val_loss: 0.1347 - val_mse: 0.1347\n",
      "Epoch 231/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0608e-04 - mse: 4.0608e-04 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 232/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0065e-04 - mse: 4.0065e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 233/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.7012e-04 - mse: 3.7012e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 234/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2808e-04 - mse: 4.2808e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 235/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8412e-04 - mse: 3.8412e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 236/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1008e-04 - mse: 4.1008e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 237/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7092e-04 - mse: 3.7092e-04 - val_loss: 0.1393 - val_mse: 0.1393\n",
      "Epoch 238/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9837e-04 - mse: 3.9837e-04 - val_loss: 0.1360 - val_mse: 0.1360\n",
      "Epoch 239/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0447e-04 - mse: 4.0447e-04 - val_loss: 0.1383 - val_mse: 0.1383\n",
      "Epoch 240/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1716e-04 - mse: 4.1716e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 241/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9966e-04 - mse: 3.9966e-04 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 242/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0259e-04 - mse: 4.0259e-04 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 243/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7579e-04 - mse: 3.7579e-04 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 244/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.8213e-04 - mse: 3.8213e-04 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 245/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0580e-04 - mse: 4.0580e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 246/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5931e-04 - mse: 4.5931e-04 - val_loss: 0.1346 - val_mse: 0.1346\n",
      "Epoch 247/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9833e-04 - mse: 3.9833e-04 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 248/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9205e-04 - mse: 3.9205e-04 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 249/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9045e-04 - mse: 3.9045e-04 - val_loss: 0.1388 - val_mse: 0.1388\n",
      "Epoch 250/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0453e-04 - mse: 4.0453e-04 - val_loss: 0.1417 - val_mse: 0.1417\n",
      "Epoch 251/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0859e-04 - mse: 4.0859e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 252/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.8057e-04 - mse: 3.8057e-04 - val_loss: 0.1358 - val_mse: 0.1358\n",
      "Epoch 253/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.8720e-04 - mse: 3.8720e-04 - val_loss: 0.1357 - val_mse: 0.1357\n",
      "Epoch 254/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.7632e-04 - mse: 3.7632e-04 - val_loss: 0.1354 - val_mse: 0.1354\n",
      "Epoch 255/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1036e-04 - mse: 4.1036e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 256/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0311e-04 - mse: 4.0311e-04 - val_loss: 0.1346 - val_mse: 0.1346\n",
      "Epoch 257/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.2099e-04 - mse: 4.2099e-04 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 258/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0381e-04 - mse: 4.0381e-04 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 259/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9986e-04 - mse: 3.9986e-04 - val_loss: 0.1405 - val_mse: 0.1405\n",
      "Epoch 260/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8052e-04 - mse: 3.8052e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 261/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0227e-04 - mse: 4.0227e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 262/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1085e-04 - mse: 4.1085e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 263/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9867e-04 - mse: 3.9867e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 264/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2377e-04 - mse: 4.2377e-04 - val_loss: 0.1406 - val_mse: 0.1406\n",
      "Epoch 265/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6536e-04 - mse: 3.6536e-04 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 266/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7720e-04 - mse: 3.7720e-04 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 267/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7234e-04 - mse: 3.7234e-04 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 268/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8413e-04 - mse: 3.8413e-04 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 269/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9116e-04 - mse: 3.9116e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 270/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2820e-04 - mse: 4.2820e-04 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 271/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9617e-04 - mse: 3.9617e-04 - val_loss: 0.1366 - val_mse: 0.1366\n",
      "Epoch 272/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9099e-04 - mse: 3.9099e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 273/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9675e-04 - mse: 3.9675e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 274/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7736e-04 - mse: 3.7736e-04 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 275/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8607e-04 - mse: 3.8607e-04 - val_loss: 0.1366 - val_mse: 0.1366\n",
      "Epoch 276/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8145e-04 - mse: 3.8145e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 277/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9602e-04 - mse: 3.9602e-04 - val_loss: 0.1360 - val_mse: 0.1360\n",
      "Epoch 278/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6757e-04 - mse: 3.6757e-04 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 279/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0535e-04 - mse: 4.0535e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 280/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7975e-04 - mse: 3.7975e-04 - val_loss: 0.1388 - val_mse: 0.1388\n",
      "Epoch 281/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6967e-04 - mse: 3.6967e-04 - val_loss: 0.1373 - val_mse: 0.1373\n",
      "Epoch 282/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8666e-04 - mse: 3.8666e-04 - val_loss: 0.1363 - val_mse: 0.1363\n",
      "Epoch 283/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9201e-04 - mse: 3.9201e-04 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 284/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9320e-04 - mse: 3.9320e-04 - val_loss: 0.1337 - val_mse: 0.1337\n",
      "Epoch 285/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8065e-04 - mse: 3.8065e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 286/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7404e-04 - mse: 3.7404e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 287/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7896e-04 - mse: 3.7896e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 288/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7394e-04 - mse: 3.7394e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 289/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6935e-04 - mse: 3.6935e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 290/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8089e-04 - mse: 3.8089e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 291/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7303e-04 - mse: 3.7303e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 292/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7507e-04 - mse: 3.7507e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 293/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1296e-04 - mse: 4.1296e-04 - val_loss: 0.1382 - val_mse: 0.1382\n",
      "Epoch 294/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7644e-04 - mse: 3.7644e-04 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 295/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6285e-04 - mse: 3.6285e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 296/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8239e-04 - mse: 3.8239e-04 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 297/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6069e-04 - mse: 3.6069e-04 - val_loss: 0.1354 - val_mse: 0.1354\n",
      "Epoch 298/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4707e-04 - mse: 3.4707e-04 - val_loss: 0.1400 - val_mse: 0.1400\n",
      "Epoch 299/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7770e-04 - mse: 3.7770e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 300/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7306e-04 - mse: 3.7306e-04 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 301/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6420e-04 - mse: 3.6420e-04 - val_loss: 0.1371 - val_mse: 0.1371\n",
      "Epoch 302/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6654e-04 - mse: 3.6654e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 303/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9878e-04 - mse: 3.9878e-04 - val_loss: 0.1399 - val_mse: 0.1399\n",
      "Epoch 304/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5488e-04 - mse: 3.5488e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 305/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6730e-04 - mse: 3.6730e-04 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 306/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5974e-04 - mse: 3.5974e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 307/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6397e-04 - mse: 3.6397e-04 - val_loss: 0.1418 - val_mse: 0.1418\n",
      "Epoch 308/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7571e-04 - mse: 3.7571e-04 - val_loss: 0.1407 - val_mse: 0.1407\n",
      "Epoch 309/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0629e-04 - mse: 4.0629e-04 - val_loss: 0.1333 - val_mse: 0.1333\n",
      "Epoch 310/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7463e-04 - mse: 3.7463e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 311/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8090e-04 - mse: 3.8090e-04 - val_loss: 0.1392 - val_mse: 0.1392\n",
      "Epoch 312/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6308e-04 - mse: 3.6308e-04 - val_loss: 0.1356 - val_mse: 0.1356\n",
      "Epoch 313/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3171e-04 - mse: 4.3171e-04 - val_loss: 0.1397 - val_mse: 0.1397\n",
      "Epoch 314/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5388e-04 - mse: 3.5388e-04 - val_loss: 0.1400 - val_mse: 0.1400\n",
      "Epoch 315/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8147e-04 - mse: 3.8147e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 316/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7084e-04 - mse: 3.7084e-04 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 317/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8260e-04 - mse: 3.8260e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 318/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0305e-04 - mse: 4.0305e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 319/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5045e-04 - mse: 3.5045e-04 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 320/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7214e-04 - mse: 3.7214e-04 - val_loss: 0.1354 - val_mse: 0.1354\n",
      "Epoch 321/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0342e-04 - mse: 4.0342e-04 - val_loss: 0.1415 - val_mse: 0.1415\n",
      "Epoch 322/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7220e-04 - mse: 3.7220e-04 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 323/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7913e-04 - mse: 3.7913e-04 - val_loss: 0.1399 - val_mse: 0.1399\n",
      "Epoch 324/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7610e-04 - mse: 3.7610e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 325/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3779e-04 - mse: 3.3779e-04 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 326/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8625e-04 - mse: 3.8625e-04 - val_loss: 0.1398 - val_mse: 0.1398\n",
      "Epoch 327/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6851e-04 - mse: 3.6851e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 328/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5588e-04 - mse: 3.5588e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 329/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6029e-04 - mse: 3.6029e-04 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 330/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5407e-04 - mse: 3.5407e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 331/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5306e-04 - mse: 3.5306e-04 - val_loss: 0.1348 - val_mse: 0.1348\n",
      "Epoch 332/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6028e-04 - mse: 3.6028e-04 - val_loss: 0.1419 - val_mse: 0.1419\n",
      "Epoch 333/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5081e-04 - mse: 3.5081e-04 - val_loss: 0.1394 - val_mse: 0.1394\n",
      "Epoch 334/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3773e-04 - mse: 3.3773e-04 - val_loss: 0.1398 - val_mse: 0.1398\n",
      "Epoch 335/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7014e-04 - mse: 3.7014e-04 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 336/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7719e-04 - mse: 3.7719e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 337/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2779e-04 - mse: 3.2779e-04 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 338/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5156e-04 - mse: 3.5156e-04 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 339/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6489e-04 - mse: 3.6489e-04 - val_loss: 0.1367 - val_mse: 0.1367\n",
      "Epoch 340/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7913e-04 - mse: 3.7913e-04 - val_loss: 0.1429 - val_mse: 0.1429\n",
      "Epoch 341/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7659e-04 - mse: 3.7659e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 342/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3862e-04 - mse: 3.3862e-04 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 343/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4294e-04 - mse: 3.4294e-04 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 344/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6684e-04 - mse: 3.6684e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 345/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4068e-04 - mse: 3.4068e-04 - val_loss: 0.1383 - val_mse: 0.1383\n",
      "Epoch 346/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4306e-04 - mse: 3.4306e-04 - val_loss: 0.1398 - val_mse: 0.1398\n",
      "Epoch 347/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7527e-04 - mse: 3.7527e-04 - val_loss: 0.1407 - val_mse: 0.1407\n",
      "Epoch 348/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9304e-04 - mse: 3.9304e-04 - val_loss: 0.1357 - val_mse: 0.1357\n",
      "Epoch 349/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4459e-04 - mse: 3.4459e-04 - val_loss: 0.1411 - val_mse: 0.1411\n",
      "Epoch 350/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5146e-04 - mse: 3.5146e-04 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 351/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2829e-04 - mse: 3.2829e-04 - val_loss: 0.1373 - val_mse: 0.1373\n",
      "Epoch 352/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3656e-04 - mse: 3.3656e-04 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 353/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3790e-04 - mse: 3.3790e-04 - val_loss: 0.1422 - val_mse: 0.1422\n",
      "Epoch 354/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7498e-04 - mse: 3.7498e-04 - val_loss: 0.1417 - val_mse: 0.1417\n",
      "Epoch 355/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2251e-04 - mse: 3.2251e-04 - val_loss: 0.1355 - val_mse: 0.1355\n",
      "Epoch 356/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4740e-04 - mse: 3.4740e-04 - val_loss: 0.1358 - val_mse: 0.1358\n",
      "Epoch 357/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3972e-04 - mse: 3.3972e-04 - val_loss: 0.1409 - val_mse: 0.1409\n",
      "Epoch 358/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6944e-04 - mse: 3.6944e-04 - val_loss: 0.1414 - val_mse: 0.1414\n",
      "Epoch 359/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5341e-04 - mse: 3.5341e-04 - val_loss: 0.1414 - val_mse: 0.1414\n",
      "Epoch 360/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4857e-04 - mse: 3.4857e-04 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 361/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5168e-04 - mse: 3.5168e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 362/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3492e-04 - mse: 3.3492e-04 - val_loss: 0.1359 - val_mse: 0.1359\n",
      "Epoch 363/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4999e-04 - mse: 3.4999e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 364/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2914e-04 - mse: 3.2914e-04 - val_loss: 0.1412 - val_mse: 0.1412\n",
      "Epoch 365/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.0803e-04 - mse: 3.0803e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 366/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3064e-04 - mse: 3.3064e-04 - val_loss: 0.1394 - val_mse: 0.1394\n",
      "Epoch 367/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8381e-04 - mse: 3.8381e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 368/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6010e-04 - mse: 3.6010e-04 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 369/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4230e-04 - mse: 3.4230e-04 - val_loss: 0.1392 - val_mse: 0.1392\n",
      "Epoch 370/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4298e-04 - mse: 3.4298e-04 - val_loss: 0.1408 - val_mse: 0.1408\n",
      "Epoch 371/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4673e-04 - mse: 3.4673e-04 - val_loss: 0.1386 - val_mse: 0.1386\n",
      "Epoch 372/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1553e-04 - mse: 3.1553e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 373/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4537e-04 - mse: 3.4537e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 374/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8076e-04 - mse: 3.8076e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 375/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3447e-04 - mse: 3.3447e-04 - val_loss: 0.1364 - val_mse: 0.1364\n",
      "Epoch 376/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1437e-04 - mse: 3.1437e-04 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 377/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6707e-04 - mse: 3.6707e-04 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 378/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4054e-04 - mse: 3.4054e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 379/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1134e-04 - mse: 3.1134e-04 - val_loss: 0.1368 - val_mse: 0.1368\n",
      "Epoch 380/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3880e-04 - mse: 3.3880e-04 - val_loss: 0.1422 - val_mse: 0.1422\n",
      "Epoch 381/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2515e-04 - mse: 3.2515e-04 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 382/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2335e-04 - mse: 3.2335e-04 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 383/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5175e-04 - mse: 3.5175e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 384/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5243e-04 - mse: 3.5243e-04 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 385/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3341e-04 - mse: 3.3341e-04 - val_loss: 0.1394 - val_mse: 0.1394\n",
      "Epoch 386/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3659e-04 - mse: 3.3659e-04 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 387/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1860e-04 - mse: 3.1860e-04 - val_loss: 0.1408 - val_mse: 0.1408\n",
      "Epoch 388/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.0779e-04 - mse: 3.0779e-04 - val_loss: 0.1380 - val_mse: 0.1380\n",
      "Epoch 389/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4656e-04 - mse: 3.4656e-04 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 390/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2773e-04 - mse: 3.2773e-04 - val_loss: 0.1382 - val_mse: 0.1382\n",
      "Epoch 391/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5196e-04 - mse: 3.5196e-04 - val_loss: 0.1341 - val_mse: 0.1341\n",
      "Epoch 392/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3553e-04 - mse: 3.3553e-04 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 393/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6894e-04 - mse: 3.6894e-04 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 394/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2659e-04 - mse: 3.2659e-04 - val_loss: 0.1360 - val_mse: 0.1360\n",
      "Epoch 395/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3861e-04 - mse: 3.3861e-04 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 396/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3297e-04 - mse: 3.3297e-04 - val_loss: 0.1383 - val_mse: 0.1383\n",
      "Epoch 397/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2429e-04 - mse: 3.2429e-04 - val_loss: 0.1371 - val_mse: 0.1371\n",
      "Epoch 398/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9572e-04 - mse: 2.9572e-04 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 399/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3163e-04 - mse: 3.3163e-04 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 400/400\n",
      "\u001b[1m387/387\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4557e-04 - mse: 3.4557e-04 - val_loss: 0.1374 - val_mse: 0.1374\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import History\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network model\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Prepare the data\n",
    "X_train = df_train[all_feature_cols].values\n",
    "y_train = df_train['t0s0'].values\n",
    "X_test = df_test_preprocessed[all_feature_cols].values\n",
    "y_test = df_test_preprocessed['t0s0'].values\n",
    "\n",
    "# Create the model\n",
    "model = create_model(X_train.shape[1])\n",
    "\n",
    "# Train the model and store the training history\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=400, batch_size=32)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step\n",
      "RMSE Neural Network: 0.3706456680608082\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "y_pred = model.predict(X_test)\n",
    "RMSE_nn = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE Neural Network:', RMSE_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install autogluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "x_train = pd.read_csv('./Xtrain.csv')\n",
    "y_train = pd.read_csv('./Ytrain.csv')\n",
    "\n",
    "x_test = pd.read_csv('./Xtest.csv')\n",
    "y_sample = pd.read_csv('./Ysample.csv')\n",
    "\n",
    "# Add t0s0 \n",
    "x_train['t0s0'] = y_train['t0s0']\n",
    "x_test['t0s0'] = y_sample['t0s0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label='t0s0').fit(train_data=x_train)\n",
    "predictions = predictor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -0.4197631785901537,\n",
       " 'mean_squared_error': -0.1762011261001093,\n",
       " 'mean_absolute_error': -0.3428852462157734,\n",
       " 'r2': -1.1380229801971264,\n",
       " 'pearsonr': -0.00034718306570084324,\n",
       " 'median_absolute_error': -0.3042307014465332}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(\"/media/arthur/HD/Users/arthu/projetos/machine-learning-for-networks/project/AutogluonModels/ag-20241211_012310\")\n",
    "\n",
    "predictor.evaluate(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.402479</td>\n",
       "      <td>-0.065125</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.088340</td>\n",
       "      <td>0.026568</td>\n",
       "      <td>0.053639</td>\n",
       "      <td>0.088340</td>\n",
       "      <td>0.026568</td>\n",
       "      <td>0.053639</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.402479</td>\n",
       "      <td>-0.083411</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.091594</td>\n",
       "      <td>0.026319</td>\n",
       "      <td>0.054304</td>\n",
       "      <td>0.091594</td>\n",
       "      <td>0.026319</td>\n",
       "      <td>0.054304</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.413552</td>\n",
       "      <td>-0.022988</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.050451</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>49.946575</td>\n",
       "      <td>0.050451</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>49.946575</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.419352</td>\n",
       "      <td>-0.015647</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.566449</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>12.843390</td>\n",
       "      <td>3.566449</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>12.843390</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.419583</td>\n",
       "      <td>-0.015766</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>118.303798</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>118.303798</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.419763</td>\n",
       "      <td>-0.014675</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>5.353852</td>\n",
       "      <td>1.015203</td>\n",
       "      <td>194.265181</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.419978</td>\n",
       "      <td>-0.015889</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.726526</td>\n",
       "      <td>0.121344</td>\n",
       "      <td>5.247526</td>\n",
       "      <td>0.726526</td>\n",
       "      <td>0.121344</td>\n",
       "      <td>5.247526</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.420019</td>\n",
       "      <td>-0.015648</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.319945</td>\n",
       "      <td>0.063056</td>\n",
       "      <td>6.720041</td>\n",
       "      <td>0.319945</td>\n",
       "      <td>0.063056</td>\n",
       "      <td>6.720041</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.420068</td>\n",
       "      <td>-0.016698</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.356590</td>\n",
       "      <td>0.100216</td>\n",
       "      <td>6.961895</td>\n",
       "      <td>0.356590</td>\n",
       "      <td>0.100216</td>\n",
       "      <td>6.961895</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.420126</td>\n",
       "      <td>-0.016041</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.919892</td>\n",
       "      <td>0.134956</td>\n",
       "      <td>9.404408</td>\n",
       "      <td>0.919892</td>\n",
       "      <td>0.134956</td>\n",
       "      <td>9.404408</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.420201</td>\n",
       "      <td>-0.016395</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.256803</td>\n",
       "      <td>0.040030</td>\n",
       "      <td>29.482225</td>\n",
       "      <td>0.256803</td>\n",
       "      <td>0.040030</td>\n",
       "      <td>29.482225</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.420237</td>\n",
       "      <td>-0.017693</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.105160</td>\n",
       "      <td>19.933036</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.105160</td>\n",
       "      <td>19.933036</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val              eval_metric  \\\n",
       "0        KNeighborsDist   -0.402479  -0.065125  root_mean_squared_error   \n",
       "1        KNeighborsUnif   -0.402479  -0.083411  root_mean_squared_error   \n",
       "2        NeuralNetTorch   -0.413552  -0.022988  root_mean_squared_error   \n",
       "3            LightGBMXT   -0.419352  -0.015647  root_mean_squared_error   \n",
       "4              CatBoost   -0.419583  -0.015766  root_mean_squared_error   \n",
       "5   WeightedEnsemble_L2   -0.419763  -0.014675  root_mean_squared_error   \n",
       "6              LightGBM   -0.419978  -0.015889  root_mean_squared_error   \n",
       "7               XGBoost   -0.420019  -0.015648  root_mean_squared_error   \n",
       "8         ExtraTreesMSE   -0.420068  -0.016698  root_mean_squared_error   \n",
       "9         LightGBMLarge   -0.420126  -0.016041  root_mean_squared_error   \n",
       "10      NeuralNetFastAI   -0.420201  -0.016395  root_mean_squared_error   \n",
       "11      RandomForestMSE   -0.420237  -0.017693  root_mean_squared_error   \n",
       "\n",
       "    pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0         0.088340       0.026568    0.053639                 0.088340   \n",
       "1         0.091594       0.026319    0.054304                 0.091594   \n",
       "2         0.050451       0.015437   49.946575                 0.050451   \n",
       "3         3.566449       0.697394   12.843390                 3.566449   \n",
       "4         0.062144       0.008797  118.303798                 0.062144   \n",
       "5         5.353852       1.015203  194.265181                 0.008684   \n",
       "6         0.726526       0.121344    5.247526                 0.726526   \n",
       "7         0.319945       0.063056    6.720041                 0.319945   \n",
       "8         0.356590       0.100216    6.961895                 0.356590   \n",
       "9         0.919892       0.134956    9.404408                 0.919892   \n",
       "10        0.256803       0.040030   29.482225                 0.256803   \n",
       "11        0.783237       0.105160   19.933036                 0.783237   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.026568           0.053639            1       True   \n",
       "1                 0.026319           0.054304            1       True   \n",
       "2                 0.015437          49.946575            1       True   \n",
       "3                 0.697394          12.843390            1       True   \n",
       "4                 0.008797         118.303798            1       True   \n",
       "5                 0.000551           0.020796            2       True   \n",
       "6                 0.121344           5.247526            1       True   \n",
       "7                 0.063056           6.720041            1       True   \n",
       "8                 0.100216           6.961895            1       True   \n",
       "9                 0.134956           9.404408            1       True   \n",
       "10                0.040030          29.482225            1       True   \n",
       "11                0.105160          19.933036            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           2  \n",
       "1           1  \n",
       "2          10  \n",
       "3           3  \n",
       "4           6  \n",
       "5          12  \n",
       "6           4  \n",
       "7           9  \n",
       "8           7  \n",
       "9          11  \n",
       "10          8  \n",
       "11          5  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preprocessed = preprocess_data(x_test, y_sample)\n",
    "df_train_preprocessed = preprocess_data(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241211_161227\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #49~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Nov  6 17:42:15 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       13.63 GB / 19.41 GB (70.2%)\n",
      "Disk Space Avail:   835.31 GB / 930.26 GB (89.8%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/media/arthur/HD/Users/arthu/projetos/machine-learning-for-networks/project/AutogluonModels/ag-20241211_161227\"\n",
      "Train Data Rows:    31119\n",
      "Train Data Columns: 52\n",
      "Label Column:       p0q0\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (0.974, 0.0, 0.24875, 0.15737)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13968.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.11 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 42 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['p1q0', 'p2q0', 'p3q0', 'p0q1', 'p0q2', ...]\n",
      "\t\t('int', [])   : 45 | ['train', 'station_AD', 'station_AI', 'station_AJ', 'station_AK', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['p1q0', 'p2q0', 'p3q0', 'p0q1', 'p0q2', ...]\n",
      "\t\t('int', [])       :  3 | ['train', 'month', 'day']\n",
      "\t\t('int', ['bool']) : 42 | ['station_AD', 'station_AI', 'station_AJ', 'station_AK', 'station_AM', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.38 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08033677174716411, Train Rows: 28619, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.0784\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.0631\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0165453\n",
      "[2000]\tvalid_set's rmse: 0.0160131\n",
      "[3000]\tvalid_set's rmse: 0.0158562\n",
      "[4000]\tvalid_set's rmse: 0.0158162\n",
      "[5000]\tvalid_set's rmse: 0.0158107\n",
      "[6000]\tvalid_set's rmse: 0.0158042\n",
      "[7000]\tvalid_set's rmse: 0.0157878\n",
      "[8000]\tvalid_set's rmse: 0.0158066\n",
      "[9000]\tvalid_set's rmse: 0.0158058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0158\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.94s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0159907\n",
      "[2000]\tvalid_set's rmse: 0.0157882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0158\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.0163\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.79s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.0154\t = Validation score   (-root_mean_squared_error)\n",
      "\t79.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.016\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.31s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.0163\t = Validation score   (-root_mean_squared_error)\n",
      "\t53.92s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.0155\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.95s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0191\t = Validation score   (-root_mean_squared_error)\n",
      "\t55.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0157198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0157\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.5s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 0.263, 'NeuralNetFastAI': 0.263, 'XGBoost': 0.263, 'RandomForestMSE': 0.158, 'ExtraTreesMSE': 0.053}\n",
      "\t-0.0146\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 275.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6753.8 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/media/arthur/HD/Users/arthu/projetos/machine-learning-for-networks/project/AutogluonModels/ag-20241211_161227\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='t0s0').fit(train_data=df_train_preprocessed)\n",
    "predictions = predictor.predict(df_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.411658</td>\n",
       "      <td>-0.078444</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.132601</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.132601</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.411716</td>\n",
       "      <td>-0.063068</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.417389</td>\n",
       "      <td>-0.019074</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>55.732796</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>55.732796</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.419894</td>\n",
       "      <td>-0.016251</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.074030</td>\n",
       "      <td>53.918774</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.074030</td>\n",
       "      <td>53.918774</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.420121</td>\n",
       "      <td>-0.015953</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.634571</td>\n",
       "      <td>0.100582</td>\n",
       "      <td>15.307039</td>\n",
       "      <td>0.634571</td>\n",
       "      <td>0.100582</td>\n",
       "      <td>15.307039</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.420380</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.821058</td>\n",
       "      <td>0.103388</td>\n",
       "      <td>31.786883</td>\n",
       "      <td>0.821058</td>\n",
       "      <td>0.103388</td>\n",
       "      <td>31.786883</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.420453</td>\n",
       "      <td>-0.014583</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.209878</td>\n",
       "      <td>0.370160</td>\n",
       "      <td>189.965324</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.420477</td>\n",
       "      <td>-0.015787</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.413312</td>\n",
       "      <td>0.675828</td>\n",
       "      <td>12.935828</td>\n",
       "      <td>3.413312</td>\n",
       "      <td>0.675828</td>\n",
       "      <td>12.935828</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.420766</td>\n",
       "      <td>-0.015782</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.109172</td>\n",
       "      <td>4.732346</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.109172</td>\n",
       "      <td>4.732346</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.420803</td>\n",
       "      <td>-0.015354</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.063236</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>79.977634</td>\n",
       "      <td>0.063236</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>79.977634</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.420868</td>\n",
       "      <td>-0.015695</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.686314</td>\n",
       "      <td>0.089114</td>\n",
       "      <td>7.501068</td>\n",
       "      <td>0.686314</td>\n",
       "      <td>0.089114</td>\n",
       "      <td>7.501068</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.420948</td>\n",
       "      <td>-0.015535</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.414101</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>8.953859</td>\n",
       "      <td>0.414101</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>8.953859</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val              eval_metric  \\\n",
       "0        KNeighborsUnif   -0.411658  -0.078444  root_mean_squared_error   \n",
       "1        KNeighborsDist   -0.411716  -0.063068  root_mean_squared_error   \n",
       "2        NeuralNetTorch   -0.417389  -0.019074  root_mean_squared_error   \n",
       "3       NeuralNetFastAI   -0.419894  -0.016251  root_mean_squared_error   \n",
       "4         ExtraTreesMSE   -0.420121  -0.015953  root_mean_squared_error   \n",
       "5       RandomForestMSE   -0.420380  -0.016335  root_mean_squared_error   \n",
       "6   WeightedEnsemble_L2   -0.420453  -0.014583  root_mean_squared_error   \n",
       "7            LightGBMXT   -0.420477  -0.015787  root_mean_squared_error   \n",
       "8              LightGBM   -0.420766  -0.015782  root_mean_squared_error   \n",
       "9              CatBoost   -0.420803  -0.015354  root_mean_squared_error   \n",
       "10        LightGBMLarge   -0.420868  -0.015695  root_mean_squared_error   \n",
       "11              XGBoost   -0.420948  -0.015535  root_mean_squared_error   \n",
       "\n",
       "    pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0         0.132601       0.024563    0.062893                 0.132601   \n",
       "1         0.151916       0.014981    0.045250                 0.151916   \n",
       "2         0.050180       0.015383   55.732796                 0.050180   \n",
       "3         0.269404       0.074030   53.918774                 0.269404   \n",
       "4         0.634571       0.100582   15.307039                 0.634571   \n",
       "5         0.821058       0.103388   31.786883                 0.821058   \n",
       "6         2.209878       0.370160  189.965324                 0.007508   \n",
       "7         3.413312       0.675828   12.935828                 3.413312   \n",
       "8         0.522667       0.109172    4.732346                 0.522667   \n",
       "9         0.063236       0.010286   79.977634                 0.063236   \n",
       "10        0.686314       0.089114    7.501068                 0.686314   \n",
       "11        0.414101       0.081269    8.953859                 0.414101   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.024563           0.062893            1       True   \n",
       "1                 0.014981           0.045250            1       True   \n",
       "2                 0.015383          55.732796            1       True   \n",
       "3                 0.074030          53.918774            1       True   \n",
       "4                 0.100582          15.307039            1       True   \n",
       "5                 0.103388          31.786883            1       True   \n",
       "6                 0.000606           0.021135            2       True   \n",
       "7                 0.675828          12.935828            1       True   \n",
       "8                 0.109172           4.732346            1       True   \n",
       "9                 0.010286          79.977634            1       True   \n",
       "10                0.089114           7.501068            1       True   \n",
       "11                0.081269           8.953859            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           1  \n",
       "1           2  \n",
       "2          10  \n",
       "3           8  \n",
       "4           7  \n",
       "5           5  \n",
       "6          12  \n",
       "7           3  \n",
       "8           4  \n",
       "9           6  \n",
       "10         11  \n",
       "11          9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(df_test_preprocessed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "b.exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
